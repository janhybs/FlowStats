{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected methods in mathematical statistics - regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from data.generator import *\n",
    "from data import filters\n",
    "from data import utils\n",
    "%precision 4\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "\n",
    " - approach for modeling the relationship between variable y and x\n",
    " - linear regression model assumes that the relationship between the dependent variable y and x is linear\n",
    " - The goal is to find the equation of the straight line:\n",
    "     - data line $y$ is represented as $y = \\beta x + \\alpha$\n",
    " \n",
    "### Example of linear regression line\n",
    "![Linear regression example](img/lin_reg.png)\n",
    "\n",
    "### Finding line coefficients $\\hat{\\beta}$ and $\\hat{\\alpha}$ using LMS\n",
    "\n",
    " - Least Mean Squares (LMS) method\n",
    " - two goals:\n",
    "   1. the maximum variance along line\n",
    "   2. the minimum error from point to line\n",
    "\n",
    "$$\\hat{\\beta} = \\sum {y_i(x - \\bar{x}}) / \\sum{(x_i - \\bar{x})^2} = \\frac{\\bar{xy} - \\bar{x}\\bar{y}} { \\bar{x^2} - \\bar{x}^2 }$$\n",
    "$$\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}$$\n",
    "\n",
    "![PCA](img/PCA.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6451998186ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# ------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m x1, y1 = generate([\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mDataConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate' is not defined"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "mu = 50\n",
    "sigma = 30\n",
    "size = 100\n",
    "scale = 2\n",
    "# ------------------------------------------------------\n",
    "x1, y1 = generate([\n",
    "    DataConfig(size, linear_generator(scale, mu, sigma))\n",
    "])\n",
    "\n",
    "x2, y2 = generate(\n",
    "     [\n",
    "         DataConfig(int(size/2), constant_generator(sigma=sigma/10)),\n",
    "         DataConfig(size - int(size/2), linear_generator(-scale, sigma=sigma/10))\n",
    "     ]\n",
    ")\n",
    "# ------------------------------------------------------\n",
    "# set size\n",
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "def regression_line(x, y):\n",
    "    beta = np.sum(y * (x - np.mean(x))) / np.sum((x - np.mean(x)) * (x - np.mean(x)))\n",
    "    alpha = np.mean(y) - (beta * np.mean(x))\n",
    "    return beta, alpha\n",
    "\n",
    "def experiment(x, y, title):\n",
    "    # plot data\n",
    "    plt.grid(True)\n",
    "    plt.scatter(x, y, c='blue', edgecolors='none', label='data')\n",
    "    plt.title(title)\n",
    "\n",
    "    # solution 1\n",
    "    b, a = regression_line(x, y)\n",
    "\n",
    "    # solution 2\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    m, c = np.linalg.lstsq(A, y)[0]\n",
    "\n",
    "    # linear regression coef\n",
    "    print ('beta, alpha = {:1.6f}, {:1.6f}'.format(b, a))\n",
    "    print ('m,    c     = {:1.6f}, {:1.6f}'.format(m, c))\n",
    "\n",
    "    # plot lines (they should be overlapping)\n",
    "    plt.plot(x, x*m + c, 'g', label='fitted line #2', lw=2.5)\n",
    "    plt.plot(x, x*b + a, 'r', label='fitted line #1', lw=2.5)\n",
    "    plt.legend();\n",
    "\n",
    "# plot experiment 1\n",
    "plt.subplot(1, 2, 1)\n",
    "experiment(x1, y1, 'Accurate fit')\n",
    "\n",
    "# plot experiment 2\n",
    "plt.subplot(1, 2, 2)\n",
    "experiment(x2, y2, 'Inaccurate fit due to data character')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression \n",
    "\n",
    " - polynomial regression is a form of linear regression in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree **polynomial**\n",
    "\n",
    "### Simple linear model:\n",
    "$y = a_0 + a_1 x + \\varepsilon$\n",
    "\n",
    "### Quadratic  model\n",
    "$y = a_0 + a_1 x + a_2 x^2 + \\varepsilon$\n",
    "\n",
    "### Polynomial regression model\n",
    "$y = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots + a_n x^n + \\varepsilon = $\n",
    "\n",
    "$\\begin{bmatrix} y_1\\\\ y_2\\\\ y_3 \\\\ \\vdots \\\\ y_n \\end{bmatrix}= \\begin{bmatrix} 1 & x_1 & x_1^2 & \\dots & x_1^m \\\\ 1 & x_2 & x_2^2 & \\dots & x_2^m \\\\ 1 & x_3 & x_3^2 & \\dots & x_3^m \\\\ \\vdots & \\vdots & \\vdots & & \\vdots \\\\ 1 & x_n & x_n^2 & \\dots & x_n^m \\end{bmatrix} \\begin{bmatrix} a_0\\\\ a_1\\\\ a_2\\\\ \\vdots \\\\ a_m \\end{bmatrix} + \\begin{bmatrix} \\varepsilon_1\\\\ \\varepsilon_2\\\\ \\varepsilon_3 \\\\ \\vdots \\\\ \\varepsilon_n \\end{bmatrix}$\n",
    "\n",
    "#### Finding coefficients $\\vec a$ using LMS\n",
    "$\\widehat{\\vec a} = (\\mathbf{X}^T \\mathbf{X})^{-1}\\; \\mathbf{X}^T \\vec y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "mu = 50\n",
    "sigma = 30\n",
    "size = 100\n",
    "scale = 2\n",
    "# ------------------------------------------------------\n",
    "x1, y1 = generate([\n",
    "    DataConfig(size, linear_generator(scale, mu, sigma))\n",
    "])\n",
    "\n",
    "x2, y2 = generate(\n",
    "     [\n",
    "         DataConfig(int(size/2), constant_generator(sigma=sigma/10)),\n",
    "         DataConfig(size - int(size/2), linear_generator(-scale, sigma=sigma/10))\n",
    "     ]\n",
    ")\n",
    "\n",
    "x3, y3 = generate(\n",
    "     [\n",
    "         DataConfig(int(size/3), constant_generator(sigma=sigma/10)),\n",
    "         DataConfig(int(size/3), linear_generator(scale, sigma=sigma/10)),\n",
    "         DataConfig(size - int(size/3)*2, constant_generator(sigma=sigma/10, mu=int(size/3) * scale)),\n",
    "     ]\n",
    ")\n",
    "# ------------------------------------------------------\n",
    "# set size\n",
    "plt.figure(figsize=(20,13))\n",
    "order_colors = ['b', 'b', 'r', 'g', 'orange'] + ['k'] * 10\n",
    "\n",
    "\n",
    "def experiment(x, y, order):\n",
    "    plt.scatter(x, y, edgecolors='none', label='data')\n",
    "    plt.grid(True)\n",
    "    X = np.vstack([x ** p for p in range(order)]).T\n",
    "    alpha = np.zeros(len(x))\n",
    "    coef = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "    print(coef)\n",
    "    \n",
    "    y_fit = sum([coef[p] * (x ** p) for p in range(order)])\n",
    "    plt.plot(x, y_fit, order_colors[order], label='order %d fit' % order,  lw=2.5)\n",
    "    plt.title('PR(order=%d): %s' % (order, utils.poly2latex(coef, digit=2)), fontsize=20)\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "orders = [2, 3]\n",
    "# plot experiment 1 and 2\n",
    "for order in orders:\n",
    "    plt.subplot(3, 2, orders.index(order) + 1)\n",
    "    experiment(x1, y1, order)\n",
    "\n",
    "# plot experiment 3 and 4\n",
    "for order in orders:\n",
    "    plt.subplot(3, 2, orders.index(order) + 3)\n",
    "    experiment(x2, y2, order)\n",
    "\n",
    "# plot experiment 5 and 6\n",
    "orders = [3, 4]\n",
    "for order in orders:\n",
    "    plt.subplot(3, 2, orders.index(order) + 5)\n",
    "    experiment(x3, y3, order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel estimate\n",
    "\n",
    "- estimating character of the dataset\n",
    "- if regression dependence is unknown we try to reveal it using kernel function $w(z)$\n",
    "- smooth dataset using kernel function which for given point $x$ returns new value. Kernel function takes into account surroundings of point $x$ (points $x_i$ where $i < d$, parameter $d$ is sometimes called *window size*\n",
    "\n",
    "### Example of different kernel functions\n",
    "![kernels](img/kernel_functions.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kernel estimate\n",
    "mu = 50\n",
    "sigma = 10\n",
    "size = 300\n",
    "scale = 0.001\n",
    "power = 2\n",
    "# ------------------------------------------------------\n",
    "data = generate([\n",
    "    DataConfig(size, exponential_generator(scale, power, mu, sigma))\n",
    "])\n",
    "\n",
    "def plot_result(data, window_size, color='red'):\n",
    "    plt.grid(True)\n",
    "    plot(data, 'b', 'scatter', edgecolor='none')\n",
    "    plot(filters.sma_filter(*data, l=window_size), color, 'plot', lw=2.5)\n",
    "    plt.title('SMA(windows_size = %d)' % window_size)\n",
    "\n",
    "# setup plot size\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Moving average filter with different window_size\n",
    "window_sizes = [3, 7, 11, 33]\n",
    "for window_size in window_sizes:\n",
    "    plt.subplot(2, 2, window_sizes.index(window_size) + 1)\n",
    "    plot_result(data, window_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
